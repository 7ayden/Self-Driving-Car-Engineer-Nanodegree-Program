{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer vision projects on classifying traffic sign. \n",
    "\n",
    "From exporation, there are 34799 training sets and 12630 testing sets. \n",
    "Each of the image has 32*32*3.\n",
    "Roughly around 40+ classes.\n",
    "The goal is to leverage a unbalance and relativity speaking small dataset to classify with deep neuarl networking.\n",
    "\n",
    "Recall from deep learning foundations course from deeplearning.ai, classic machine learning requires around 100-10,000 samples and deep learning requires around 1 million sample. \n",
    "\n",
    "Given neural network does not require any data balance having each class, I would like to see the difference between data split and also data size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (34799, 32, 32, 3)\n",
      "X_test shape (12630, 32, 32, 3)\n",
      "Y_valid shape (12630, 32, 32, 3)\n",
      "Y_valid shape (12630,)\n",
      "Y_train shape (34799, 32, 32, 3)\n",
      "Y_test shape (12630, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "training_file = \"./traffic-signs-data/train.p\"\n",
    "validation_file = \"./traffic-signs-data/test.p\"\n",
    "testing_file = \"./traffic-signs-data/test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "    \n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, Y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "#signnames = pd.read_csv('signnames.csv')\n",
    "with open('signnames.csv', mode='r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)  # skip the header\n",
    "    signnames = {rows[0]: rows[1] for rows in reader}\n",
    "label_names = list(signnames)\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"Y_valid shape\", X_valid.shape)\n",
    "print(\"Y_valid shape\", Y_valid.shape)\n",
    "print(\"Y_train shape\", X_train.shape)\n",
    "print(\"Y_test shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'Speed limit (20km/h)',\n",
       " '1': 'Speed limit (30km/h)',\n",
       " '10': 'No passing for vehicles over 3.5 metric tons',\n",
       " '11': 'Right-of-way at the next intersection',\n",
       " '12': 'Priority road',\n",
       " '13': 'Yield',\n",
       " '14': 'Stop',\n",
       " '15': 'No vehicles',\n",
       " '16': 'Vehicles over 3.5 metric tons prohibited',\n",
       " '17': 'No entry',\n",
       " '18': 'General caution',\n",
       " '19': 'Dangerous curve to the left',\n",
       " '2': 'Speed limit (50km/h)',\n",
       " '20': 'Dangerous curve to the right',\n",
       " '21': 'Double curve',\n",
       " '22': 'Bumpy road',\n",
       " '23': 'Slippery road',\n",
       " '24': 'Road narrows on the right',\n",
       " '25': 'Road work',\n",
       " '26': 'Traffic signals',\n",
       " '27': 'Pedestrians',\n",
       " '28': 'Children crossing',\n",
       " '29': 'Bicycles crossing',\n",
       " '3': 'Speed limit (60km/h)',\n",
       " '30': 'Beware of ice/snow',\n",
       " '31': 'Wild animals crossing',\n",
       " '32': 'End of all speed and passing limits',\n",
       " '33': 'Turn right ahead',\n",
       " '34': 'Turn left ahead',\n",
       " '35': 'Ahead only',\n",
       " '36': 'Go straight or right',\n",
       " '37': 'Go straight or left',\n",
       " '38': 'Keep right',\n",
       " '39': 'Keep left',\n",
       " '4': 'Speed limit (70km/h)',\n",
       " '40': 'Roundabout mandatory',\n",
       " '41': 'End of no passing',\n",
       " '42': 'End of no passing by vehicles over 3.5 metric tons',\n",
       " '5': 'Speed limit (80km/h)',\n",
       " '6': 'End of speed limit (80km/h)',\n",
       " '7': 'Speed limit (100km/h)',\n",
       " '8': 'Speed limit (120km/h)',\n",
       " '9': 'No passing'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signnames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'SignName'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-70baf0b1b6b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSignName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#plt.yticks(list(map(lambda x: label_dict[x], y_train['label'].value_counts().index.tolist())))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'SignName'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_df = pd.DataFrame()\n",
    "y_train_df['label'] = y_train\n",
    "\n",
    "# Get current size\n",
    "figsize=(15, 7)\n",
    " \n",
    "# Prints: [8.0, 6.0]\n",
    "names = list(signnames)\n",
    "item, count = np.unique(y_train, return_counts=True)\n",
    "freq = np.array((item, count)).T\n",
    "plt.figure(11)\n",
    "plt.yticks(range(len(y_train)), names.SignName)\n",
    "#plt.yticks(list(map(lambda x: label_dict[x], y_train['label'].value_counts().index.tolist())))            \n",
    "plt.barh(item, count, alpha=0.3)\n",
    "plt.title('Traffic Sign Data Distrubition')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I am planning to preprocess my image by converting into greyscale that can save a lot of computer power from 3 channels to 1, since I dont have GPU on my laptop nor planning to train on cloud. \n",
    "Next step is to normalizied dataset, the process would allows each dimensions have a similar scale\n",
    "\n",
    "\n",
    "there are always different approches on this: \n",
    "1. loop image one by one with CV2 (easiest way)\n",
    "2. passing through normalizing (pixel - 128)/ 128, then img.astype(np.float32), passing through the CV2, and finally reshape from 32,32,3 to 32,32,1\n",
    "X_train_gray = np.zeros((N, 32, 32, 1), dtype=np.float32)\n",
    "\n",
    "- in your for loop\n",
    "X_train_gray[i] = normalize_img(element)\n",
    "\n",
    "https://discourse-cdn-sjc3.com/udacity/uploads/default/original/4X/5/7/1/5719666845aa31c56610cb2c27f4a16c7fc4c022.png\n",
    "3. converting RGB to YCbCr (Y: Luminance; Cb: Chrominance-Blue; and Cr: Chrominance-Red are the components. Luminance is very similar to the grayscale version of the original image)\n",
    "\n",
    "\n",
    "3.from image_preprocessor import ImagePreprocessor\n",
    "\n",
    "image_preprocessor = ImagePreprocessor()\n",
    "image_preprocessor.call() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def normalize(img):\n",
    "#    img = (img- 128)/128\n",
    "#    return img.astype(np.float32)\n",
    "#old preprocessing\n",
    "def preprocess(img):\n",
    "    img = np.sum(img/3, axis=3, keepdims = True)\n",
    "    img = img.astype(float) / 255.0\n",
    "    return np.array(img).reshape((-1,32,32,1)) \n",
    "\n",
    "\n",
    "#def preprocess(img):\n",
    "#    image= [] \n",
    "#    for i in img:\n",
    "#        image.append(normalize(i))\n",
    "#    return np.array(image).reshape((-1,32,32,1))  \n",
    "\n",
    "\n",
    "#def preprocess(img):\n",
    "    #normalizations \n",
    "#    image = []\n",
    "#    for i in range(0,len(img)):\n",
    "#        images = img[i]\n",
    "#        cv2.cvtColor(img[i], cv2.COLOR_BGR2YCrCb)\n",
    "#        cv2.normalize(images, images, 0, 10, norm_type=cv2.NORM_MINMAX)\n",
    "#        image.append(images)\n",
    "#    return np.reshape(image, (-1, 32, 32, 1))\n",
    "\n",
    "        #resized_image = cv2.resize(img, (32, 32)) \n",
    "        #np.array(img[i]).reshape((-1,32,32,1)) \n",
    "        #image.append(normalize(grayscale(img[i])))\n",
    "    #img = (img-128)/128\n",
    "    #img = np.array(img / 255.0 - 0.5 )\n",
    "    #img = np.sum(img/3, axis=3, keepdims = True)\n",
    "    #img = img.astype(float) / 255.0\n",
    "\n",
    "X_train= preprocess(X_train)\n",
    "X_test= preprocess(X_test)\n",
    "X_valid = preprocess(X_valid)\n",
    "n_classes = len(np.unique(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (34103, 32, 32, 1)\n",
      "X_test shape (12630, 32, 32, 1)\n",
      "Y_valid shape (696, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "#shuffle the data afterwards \n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.02, random_state=0)\n",
    "\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"Y_valid shape\", X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#each time it will show a different image\n",
    "import random\n",
    "def showImg(data):\n",
    "    random = np.random.randint(len(data))\n",
    "    image = data[random].squeeze()\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    \n",
    "showImg(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#first plug into CNN and see how does the accuracy goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying leNet in Tensorflow\n",
    "\n",
    "from tensorflow.contrib.layers import flatten\n",
    "def LeNet(x):    \n",
    "    \n",
    "    # TODO: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    W1 = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma), name=\"W1\")\n",
    "    x = tf.nn.conv2d(x, W1, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    b1 = tf.Variable(tf.zeros(6), name=\"b1\")\n",
    "    x = tf.nn.bias_add(x, b1)\n",
    "    print(\"layer 1 shape:\",x.get_shape())\n",
    "\n",
    "    # TODO: Activation.\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    # TODO: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    x = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    layer1 = x\n",
    "    \n",
    "    # TODO: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    W2 = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma), name=\"W2\")\n",
    "    x = tf.nn.conv2d(x, W2, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    b2 = tf.Variable(tf.zeros(16), name=\"b2\")\n",
    "    x = tf.nn.bias_add(x, b2)\n",
    "                     \n",
    "    # TODO: Activation.\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    # TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    x = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    layer2 = x\n",
    "    \n",
    "    # TODO: Layer 3: Convolutional. Output = 1x1x400.\n",
    "    W3 = tf.Variable(tf.truncated_normal(shape=(5, 5, 16, 400), mean = mu, stddev = sigma), name=\"W3\")\n",
    "    x = tf.nn.conv2d(x, W3, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    b3 = tf.Variable(tf.zeros(400), name=\"b3\")\n",
    "    x = tf.nn.bias_add(x, b3)\n",
    "                     \n",
    "    # TODO: Activation.\n",
    "    x = tf.nn.relu(x)\n",
    "    layer3 = x\n",
    "\n",
    "    # TODO: Flatten. Input = 5x5x16. Output = 400.\n",
    "    layer2flat = flatten(layer2)\n",
    "    print(\"layer2flat shape:\",layer2flat.get_shape())\n",
    "    \n",
    "    # Flatten x. Input = 1x1x400. Output = 400.\n",
    "    xflat = flatten(x)\n",
    "    print(\"xflat shape:\",xflat.get_shape())\n",
    "    \n",
    "    # Concat layer2flat and x. Input = 400 + 400. Output = 800\n",
    "    x = tf.concat_v2([xflat, layer2flat], 1)\n",
    "    print(\"x shape:\",x.get_shape())\n",
    "    \n",
    "    # Dropout\n",
    "    x = tf.nn.dropout(x, keep_prob)\n",
    "    \n",
    "    # TODO: Layer 4: Fully Connected. Input = 800. Output = 43.\n",
    "    W4 = tf.Variable(tf.truncated_normal(shape=(800, 43), mean = mu, stddev = sigma), name=\"W4\")\n",
    "    b4 = tf.Variable(tf.zeros(43), name=\"b4\")    \n",
    "    logits = tf.add(tf.matmul(x, W4), b4)\n",
    "    \n",
    "    # TODO: Activation.\n",
    "    #x = tf.nn.relu(x)\n",
    "\n",
    "    # TODO: Layer 5: Fully Connected. Input = 120. Output = 84.\n",
    "    #W5 = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    #b5 = tf.Variable(tf.zeros(84)) \n",
    "    #x = tf.add(tf.matmul(x, W5), b5)\n",
    "    \n",
    "    # TODO: Activation.\n",
    "    #x = tf.nn.relu(x)\n",
    "\n",
    "    # TODO: Layer 6: Fully Connected. Input = 84. Output = 43.\n",
    "    #W6 = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    #b6 = tf.Variable(tf.zeros(43)) \n",
    "    #logits = tf.add(tf.matmul(x, W6), b6)\n",
    "    \n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(BATCH_SIZE, height, width, depth)\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "\n",
    "# Placeholder for labels\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "\n",
    "# One-hot encoding of labels\n",
    "one_hot_y = tf.one_hot(y, 43)\n",
    "\n",
    "# Probability to keep units\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 shape: (?, 28, 28, 6)\n",
      "layer2flat shape: (?, 400)\n",
      "xflat shape: (?, 400)\n",
      "x shape: (?, 800)\n"
     ]
    }
   ],
   "source": [
    "# Learning rate\n",
    "rate = 0.001\n",
    "mu = 0 \n",
    "sigma = 0.1\n",
    "# Pass input data to the LeNet function\n",
    "logits = LeNet(x)\n",
    "\n",
    "# Compare logits to the ground-truth labels and calculate the cross entropy\n",
    "# Cross entopy is a measure how different the logits\n",
    "# are from the ground-truth training labels\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = one_hot_y)\n",
    "# Average the cross entropy from all the training images\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "# Use Adam algorithm (alternative of stochastic gradient descent)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "# Optimizer uses backpropagation to update the network and minimize training loss\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the logit prediction to the one hot encoded ground-truth label\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "# Calculate the model's overall accuracy by averaging the individual prediction accuracies\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict = {x: batch_x, y: batch_y, keep_prob: 1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in progress...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Training Accuracy = 0.91599\n",
      "Validation Accuracy = 0.83325\n",
      "\n",
      "EPOCH 2 ...\n",
      "Training Accuracy = 0.95648\n",
      "Validation Accuracy = 0.87245\n",
      "\n",
      "EPOCH 3 ...\n",
      "Training Accuracy = 0.98109\n",
      "Validation Accuracy = 0.88804\n",
      "\n",
      "EPOCH 4 ...\n",
      "Training Accuracy = 0.98534\n",
      "Validation Accuracy = 0.89089\n",
      "\n",
      "EPOCH 5 ...\n",
      "Training Accuracy = 0.98405\n",
      "Validation Accuracy = 0.90198\n",
      "\n",
      "EPOCH 6 ...\n",
      "Training Accuracy = 0.99490\n",
      "Validation Accuracy = 0.91156\n",
      "\n",
      "EPOCH 7 ...\n",
      "Training Accuracy = 0.99704\n",
      "Validation Accuracy = 0.91544\n",
      "\n",
      "EPOCH 8 ...\n",
      "Training Accuracy = 0.99622\n",
      "Validation Accuracy = 0.91481\n",
      "\n",
      "EPOCH 9 ...\n",
      "Training Accuracy = 0.99675\n",
      "Validation Accuracy = 0.91370\n",
      "\n",
      "EPOCH 10 ...\n",
      "Training Accuracy = 0.99631\n",
      "Validation Accuracy = 0.91227\n",
      "\n",
      "EPOCH 11 ...\n",
      "Training Accuracy = 0.99645\n",
      "Validation Accuracy = 0.91441\n",
      "\n",
      "EPOCH 12 ...\n",
      "Training Accuracy = 0.99798\n",
      "Validation Accuracy = 0.91908\n",
      "\n",
      "EPOCH 13 ...\n",
      "Training Accuracy = 0.99900\n",
      "Validation Accuracy = 0.92423\n",
      "\n",
      "EPOCH 14 ...\n",
      "Training Accuracy = 0.99704\n",
      "Validation Accuracy = 0.91457\n",
      "\n",
      "EPOCH 15 ...\n",
      "Training Accuracy = 0.99642\n",
      "Validation Accuracy = 0.91504\n",
      "\n",
      "EPOCH 16 ...\n",
      "Training Accuracy = 0.99812\n",
      "Validation Accuracy = 0.91861\n",
      "\n",
      "EPOCH 17 ...\n",
      "Training Accuracy = 0.99971\n",
      "Validation Accuracy = 0.92692\n",
      "\n",
      "EPOCH 18 ...\n",
      "Training Accuracy = 0.99349\n",
      "Validation Accuracy = 0.90958\n",
      "\n",
      "EPOCH 19 ...\n",
      "Training Accuracy = 0.99821\n",
      "Validation Accuracy = 0.92352\n",
      "\n",
      "EPOCH 20 ...\n",
      "Training Accuracy = 0.99865\n",
      "Validation Accuracy = 0.92130\n",
      "\n",
      "EPOCH 21 ...\n",
      "Training Accuracy = 0.99713\n",
      "Validation Accuracy = 0.91789\n",
      "\n",
      "EPOCH 22 ...\n",
      "Training Accuracy = 0.99915\n",
      "Validation Accuracy = 0.92613\n",
      "\n",
      "EPOCH 23 ...\n",
      "Training Accuracy = 0.99545\n",
      "Validation Accuracy = 0.91544\n",
      "\n",
      "EPOCH 24 ...\n",
      "Training Accuracy = 0.99962\n",
      "Validation Accuracy = 0.93167\n",
      "\n",
      "EPOCH 25 ...\n",
      "Training Accuracy = 0.99903\n",
      "Validation Accuracy = 0.92763\n",
      "\n",
      "EPOCH 26 ...\n",
      "Training Accuracy = 0.99202\n",
      "Validation Accuracy = 0.91196\n",
      "\n",
      "EPOCH 27 ...\n",
      "Training Accuracy = 0.99921\n",
      "Validation Accuracy = 0.93262\n",
      "\n",
      "EPOCH 28 ...\n",
      "Training Accuracy = 0.99906\n",
      "Validation Accuracy = 0.92771\n",
      "\n",
      "EPOCH 29 ...\n",
      "Training Accuracy = 0.99985\n",
      "Validation Accuracy = 0.93246\n",
      "\n",
      "EPOCH 30 ...\n",
      "Training Accuracy = 1.00000\n",
      "Validation Accuracy = 0.93515\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Create the TensorFlow session and Initialize the variables\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training in progress...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        # Shuffle the training data to ensure that trainint isn't biased\n",
    "        # by the order of the images\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        # Break training data into batches and train the model on the each batch\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict = {x: batch_x, y: batch_y, keep_prob: 1.0})\n",
    "        \n",
    "        # In the end of each EPOCH evaluate the model on validation data\n",
    "        training_accuracy = evaluate(X_train, y_train)\n",
    "        validation_accuracy = evaluate(X_valid, Y_valid)\n",
    "        print(\"EPOCH {0} ...\".format(i + 1))\n",
    "        print(\"Training Accuracy = {:.5f}\".format(training_accuracy))\n",
    "        print(\"Validation Accuracy = {:.5f}\".format(validation_accuracy))\n",
    "        print()\n",
    "    \n",
    "    # Save the model\n",
    "    try:\n",
    "        saver\n",
    "    except NameError:\n",
    "        saver = tf.train.Saver()\n",
    "    saver.save(sess, 'lenet_sign_classifier')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy = 1.00000\n",
      "Validation Accuracy = 0.93515\n"
     ]
    }
   ],
   "source": [
    "#saver = tf.train.Saver()\n",
    "\n",
    "with  tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    train_accuracy = evaluate(X_train, y_train)\n",
    "    print(\"Train Accuracy = {:.5f}\".format(train_accuracy))\n",
    "    valid_accuracy = evaluate(X_valid, Y_valid)\n",
    "    print(\"Validation Accuracy = {:.5f}\".format(valid_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy = 1.00000\n"
     ]
    }
   ],
   "source": [
    "with  tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    Test_accuracy = evaluate(X_train, y_train)\n",
    "    print(\"Test Accuracy = {:.5f}\".format(Test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have been playing around with different preprocessing such as grayscale, normalize and reshaping. Tho Training accuracy has a 0.996 accuracy and Validation has close to 0.914 accuracy, yet it seems low. \n",
    "in this case, I am planning to generated more data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.) For reference on how to build a deep neural network using TensorFlow, see Deep Neural Network in TensorFlow from the classroom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: 1x1 convolution (+relu) in order for TF to calculate which channel to use\n",
    "2: 3x3 convolution (+relu) with 32 outputs\n",
    "3: 3x3 convolution (+relu) with 32 outputs\n",
    "4: 3x3 convolution (+relu) with 32 outputs\n",
    "5: 2x2 MaxPool (with stride 2) that reduces the image size to 16x16\n",
    "6: Dropout (0.5 during training, 1.0 during validation / testing)\n",
    "7: 3x3 convolution (+relu) with 64 outputs\n",
    "8: 3x3 convolution (+relu) with 64 outputs\n",
    "9: 3x3 convolution (+relu) with 64 outputs\n",
    "10: 2x2 MaxPool (with stride 2) that reduces the image size to 8x8\n",
    "11: Dropout (0.5 during training, 1.0 during validation / testing)\n",
    "12: Fully connected layer (+relu) with flattened inputs from step 6 and 11 with 12288 inputs and 512 outputs\n",
    "13: Dropout (0.5 during training, 1.0 during validation / testing)\n",
    "14: Fully connected layer (+relu) with 512 inputs and 43 (class) outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.contrib.layers import flatten\n",
    "KEEP_PROB = 0.5\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[3, strides, strides, 1], padding='VALID')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='VALID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all network parameters# Define \n",
    "mu = 0\n",
    "sigma = 0.1\n",
    "\n",
    "# and training parameters\n",
    "epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying leNet in Tensorflow\n",
    "\n",
    "from tensorflow.contrib.layers import flatten\n",
    "def LeNet(x):    \n",
    "    \n",
    "    # TODO: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    W1 = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma), name=\"W1\")\n",
    "    x = tf.nn.conv2d(x, W1, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    b1 = tf.Variable(tf.zeros(6), name=\"b1\")\n",
    "    x = tf.nn.bias_add(x, b1)\n",
    "    print(\"layer 1 shape:\",x.get_shape())\n",
    "\n",
    "    # TODO: Activation.\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    # TODO: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    x = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    layer1 = x\n",
    "    \n",
    "    # TODO: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    W2 = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma), name=\"W2\")\n",
    "    x = tf.nn.conv2d(x, W2, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    b2 = tf.Variable(tf.zeros(16), name=\"b2\")\n",
    "    x = tf.nn.bias_add(x, b2)\n",
    "                     \n",
    "    # TODO: Activation.\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    # TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    x = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    layer2 = x\n",
    "    \n",
    "    # TODO: Layer 3: Convolutional. Output = 1x1x400.\n",
    "    W3 = tf.Variable(tf.truncated_normal(shape=(5, 5, 16, 400), mean = mu, stddev = sigma), name=\"W3\")\n",
    "    x = tf.nn.conv2d(x, W3, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    b3 = tf.Variable(tf.zeros(400), name=\"b3\")\n",
    "    x = tf.nn.bias_add(x, b3)\n",
    "                     \n",
    "    # TODO: Activation.\n",
    "    x = tf.nn.relu(x)\n",
    "    layer3 = x\n",
    "\n",
    "    # TODO: Flatten. Input = 5x5x16. Output = 400.\n",
    "    layer2flat = flatten(layer2)\n",
    "    print(\"layer2flat shape:\",layer2flat.get_shape())\n",
    "    \n",
    "    # Flatten x. Input = 1x1x400. Output = 400.\n",
    "    xflat = flatten(x)\n",
    "    print(\"xflat shape:\",xflat.get_shape())\n",
    "    \n",
    "    # Concat layer2flat and x. Input = 400 + 400. Output = 800\n",
    "    x = tf.concat_v2([xflat, layer2flat], 1)\n",
    "    print(\"x shape:\",x.get_shape())\n",
    "    \n",
    "    # Dropout\n",
    "    x = tf.nn.dropout(x, keep_prob)\n",
    "    \n",
    "    # TODO: Layer 4: Fully Connected. Input = 800. Output = 43.\n",
    "    W4 = tf.Variable(tf.truncated_normal(shape=(800, 43), mean = mu, stddev = sigma), name=\"W4\")\n",
    "    b4 = tf.Variable(tf.zeros(43), name=\"b4\")    \n",
    "    logits = tf.add(tf.matmul(x, W4), b4)\n",
    "    \n",
    "    # TODO: Activation.\n",
    "    #x = tf.nn.relu(x)\n",
    "\n",
    "    # TODO: Layer 5: Fully Connected. Input = 120. Output = 84.\n",
    "    #W5 = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    #b5 = tf.Variable(tf.zeros(84)) \n",
    "    #x = tf.add(tf.matmul(x, W5), b5)\n",
    "    \n",
    "    # TODO: Activation.\n",
    "    #x = tf.nn.relu(x)\n",
    "\n",
    "    # TODO: Layer 6: Fully Connected. Input = 84. Output = 43.\n",
    "    #W6 = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    #b6 = tf.Variable(tf.zeros(43)) \n",
    "    #logits = tf.add(tf.matmul(x, W6), b6)\n",
    "    \n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#features and labels\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32,1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "keep_prob = tf.placeholder(tf.float32) \n",
    "one_hot_y = tf.one_hot(y, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting learning rate, loss functions, and optimizer\n",
    "#training pipelines\n",
    "rate = 0.004\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Question 3\n",
    "What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.) For reference on how to build a deep neural network using TensorFlow, see Deep Neural Network in TensorFlow from the classroom.\n",
    "\n",
    "5x5 convolution (32x32x1 in, 28x28x6 out)\n",
    "ReLU\n",
    "2x2 max pool (28x28x6 in, 14x14x6 out)\n",
    "5x5 convolution (14x14x6 in, 10x10x16 out)\n",
    "ReLU\n",
    "2x2 max pool (10x10x16 in, 5x5x16 out)\n",
    "5x5 convolution (5x5x6 in, 1x1x400 out)\n",
    "ReLu\n",
    "Flatten layers from numbers 8 (1x1x400 -> 400) and 6 (5x5x16 -> 400)\n",
    "Concatenate flattened layers to a single size-800 layer\n",
    "Dropout layer\n",
    "Fully connected layer (800 in, 43 out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ref:\n",
    "https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#plug in web found image and see how work does the classifer work along with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32, 32, 1)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import os\n",
    "label = np.zeros([28,35,25,9,25])\n",
    "im1 = './traffic-signs-data/germansign/image1.jpg'\n",
    "im2 = './traffic-signs-data/germansign/image2.jpg'\n",
    "im3 = './traffic-signs-data/germansign/image3.jpg'\n",
    "im4 = './traffic-signs-data/germansign/image4.jpg'\n",
    "im5 = './traffic-signs-data/germansign/image5.jpg'\n",
    "im_paths = [im1, im2, im3, im4, im5]\n",
    "new_images = []\n",
    "images = np.empty((0,32,32,3), dtype='float32')\n",
    "\n",
    "for i in im_paths:\n",
    "    img = cv2.imread(i)\n",
    "    img = cv2.resize(img, (32,32))\n",
    "    images = np.concatenate((images, img[np.newaxis,:,:,:]))\n",
    "    \n",
    "preprocessed_img = preprocess(images)\n",
    "preprocessed_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_5' with dtype float\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_5', defined at:\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-aa8d332546ca>\", line 11, in <module>\n    keep_prob = tf.placeholder(tf.float32)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1587, in placeholder\n    name=name)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2043, in _placeholder\n    name=name)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_5' with dtype float\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_5' with dtype float\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-17811052adba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpredicted_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpreprocessed_img\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy = {:.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_5' with dtype float\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_5', defined at:\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-aa8d332546ca>\", line 11, in <module>\n    keep_prob = tf.placeholder(tf.float32)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1587, in placeholder\n    name=name)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2043, in _placeholder\n    name=name)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_5' with dtype float\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    accuracy = evaluate(preprocessed_img, label)\n",
    "    predicted_logits = sess.run(logits, feed_dict={x:preprocessed_img})\n",
    "    predicted_labels = np.argmax(predicted_logits, axis=1)\n",
    "    print(\"Accuracy = {:.5f}\".format(predicted_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_5' with dtype float\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_5', defined at:\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-aa8d332546ca>\", line 11, in <module>\n    keep_prob = tf.placeholder(tf.float32)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1587, in placeholder\n    name=name)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2043, in _placeholder\n    name=name)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_5' with dtype float\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_5' with dtype float\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-a6f66118e237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msoftmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpreprocessed_img\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_5' with dtype float\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_5', defined at:\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-aa8d332546ca>\", line 11, in <module>\n    keep_prob = tf.placeholder(tf.float32)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1587, in placeholder\n    name=name)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2043, in _placeholder\n    name=name)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/jaydenmilton/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_5' with dtype float\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    result = sess.run(softmax, feed_dict={x:preprocessed_img})\n",
    "    values, indices = tf.nn.top_k(result, 5)\n",
    "    probs = sess.run(values)\n",
    "    predictions = sess.run(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Fetch argument array([[0.00000000e+00, 1.40101414e-33, 5.43279379e-29, 3.87108344e-26,\n        0.00000000e+00, 4.95622686e-30, 2.34371327e-21, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.47682202e-01,\n        9.72756092e-26, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 6.31772204e-30, 2.16958938e-22,\n        5.23177907e-02, 3.34009441e-30, 0.00000000e+00, 2.20044403e-16,\n        6.80392925e-24, 2.25714506e-21, 4.83632757e-35, 1.77089619e-14,\n        3.33382844e-13, 3.43466841e-27, 2.53261430e-19, 1.03979583e-33,\n        1.52798402e-20, 0.00000000e+00, 2.40591906e-36, 7.70013756e-23,\n        2.73661780e-23, 2.85583551e-36, 6.66731212e-33, 0.00000000e+00,\n        6.26183772e-31, 2.34085388e-21, 7.10962681e-31],\n       [1.63564700e-38, 4.10929192e-21, 2.46628016e-28, 0.00000000e+00,\n        0.00000000e+00, 1.04991758e-34, 0.00000000e+00, 0.00000000e+00,\n        6.53297585e-28, 0.00000000e+00, 0.00000000e+00, 1.59157148e-37,\n        1.89683808e-26, 3.73017101e-26, 1.42807095e-35, 1.92659863e-26,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 1.28613752e-31, 0.00000000e+00,\n        0.00000000e+00, 4.00409433e-38, 0.00000000e+00, 0.00000000e+00,\n        1.94693321e-31, 0.00000000e+00, 4.49998722e-14, 2.58777789e-27,\n        7.09710913e-35, 7.52382062e-30, 1.00000000e+00, 0.00000000e+00,\n        1.00509845e-29, 1.79652018e-34, 0.00000000e+00],\n       [7.11441386e-24, 1.37920216e-17, 2.75055552e-14, 1.73352408e-13,\n        8.53576851e-27, 5.10532630e-07, 5.56698045e-17, 1.23362480e-30,\n        6.85498617e-37, 2.58447170e-20, 9.97618377e-01, 7.25472364e-06,\n        5.86854204e-17, 1.09830829e-18, 2.35635969e-27, 3.12018683e-31,\n        1.76528397e-26, 1.38170702e-27, 1.21736822e-26, 2.67567176e-20,\n        4.56804625e-13, 6.13418550e-14, 3.58439210e-21, 3.74903516e-15,\n        1.07501935e-21, 2.37379526e-03, 9.97893933e-13, 5.67676638e-29,\n        2.66118342e-30, 2.76696568e-19, 2.45929399e-17, 3.20988980e-15,\n        1.34981579e-23, 3.15481863e-08, 1.15282530e-22, 1.62811034e-07,\n        1.13790290e-10, 1.06609833e-17, 3.30661288e-19, 1.36794613e-26,\n        5.57576061e-16, 1.87231768e-13, 7.18081629e-21],\n       [2.17307256e-15, 1.00000000e+00, 2.92663717e-27, 0.00000000e+00,\n        2.02870508e-37, 7.36693588e-37, 7.36910408e-21, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.27373323e-09,\n        2.15949103e-34, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 2.25538752e-08, 0.00000000e+00,\n        4.76529717e-29, 0.00000000e+00, 0.00000000e+00, 1.54293877e-38,\n        1.93305253e-36, 1.43101418e-37, 3.55601276e-35, 1.32614119e-28,\n        0.00000000e+00, 3.43878553e-31, 0.00000000e+00, 1.57140941e-30,\n        2.43764877e-36, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 6.72256324e-27, 0.00000000e+00, 0.00000000e+00,\n        2.96716232e-12, 1.65405285e-35, 0.00000000e+00],\n       [0.00000000e+00, 2.51641452e-25, 5.37897252e-33, 0.00000000e+00,\n        0.00000000e+00, 3.54387096e-32, 2.72795164e-31, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n        1.71728979e-25, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.25136065e-38,\n        6.93658647e-22, 5.31652585e-34, 0.00000000e+00, 1.17289251e-31,\n        4.29902308e-18, 1.78873400e-16, 9.90735615e-38, 4.99272235e-10,\n        1.79707568e-26, 3.19192749e-31, 2.16158398e-08, 0.00000000e+00,\n        2.30670700e-34, 4.87379789e-38, 1.76524846e-21, 4.00485804e-38,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        7.04501177e-38, 2.98800520e-27, 1.83396896e-32]], dtype=float32) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    266\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 267\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    268\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2317\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2406\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\"\n\u001b[0;32m-> 2407\u001b[0;31m                       % (type(obj).__name__, types_str))\n\u001b[0m\u001b[1;32m   2408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not convert a ndarray into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-48781fcb92d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Accuracy = {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpreprocessed_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m     \u001b[0mfetch_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \"\"\"\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    269\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[1;32m    270\u001b[0m                         \u001b[0;34m'must be a string or Tensor. (%s)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                         % (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[1;32m    272\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mTypeError\u001b[0m: Fetch argument array([[0.00000000e+00, 1.40101414e-33, 5.43279379e-29, 3.87108344e-26,\n        0.00000000e+00, 4.95622686e-30, 2.34371327e-21, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.47682202e-01,\n        9.72756092e-26, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 6.31772204e-30, 2.16958938e-22,\n        5.23177907e-02, 3.34009441e-30, 0.00000000e+00, 2.20044403e-16,\n        6.80392925e-24, 2.25714506e-21, 4.83632757e-35, 1.77089619e-14,\n        3.33382844e-13, 3.43466841e-27, 2.53261430e-19, 1.03979583e-33,\n        1.52798402e-20, 0.00000000e+00, 2.40591906e-36, 7.70013756e-23,\n        2.73661780e-23, 2.85583551e-36, 6.66731212e-33, 0.00000000e+00,\n        6.26183772e-31, 2.34085388e-21, 7.10962681e-31],\n       [1.63564700e-38, 4.10929192e-21, 2.46628016e-28, 0.00000000e+00,\n        0.00000000e+00, 1.04991758e-34, 0.00000000e+00, 0.00000000e+00,\n        6.53297585e-28, 0.00000000e+00, 0.00000000e+00, 1.59157148e-37,\n        1.89683808e-26, 3.73017101e-26, 1.42807095e-35, 1.92659863e-26,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 1.28613752e-31, 0.00000000e+00,\n        0.00000000e+00, 4.00409433e-38, 0.00000000e+00, 0.00000000e+00,\n        1.94693321e-31, 0.00000000e+00, 4.49998722e-14, 2.58777789e-27,\n        7.09710913e-35, 7.52382062e-30, 1.00000000e+00, 0.00000000e+00,\n        1.00509845e-29, 1.79652018e-34, 0.00000000e+00],\n       [7.11441386e-24, 1.37920216e-17, 2.75055552e-14, 1.73352408e-13,\n        8.53576851e-27, 5.10532630e-07, 5.56698045e-17, 1.23362480e-30,\n        6.85498617e-37, 2.58447170e-20, 9.97618377e-01, 7.25472364e-06,\n        5.86854204e-17, 1.09830829e-18, 2.35635969e-27, 3.12018683e-31,\n        1.76528397e-26, 1.38170702e-27, 1.21736822e-26, 2.67567176e-20,\n        4.56804625e-13, 6.13418550e-14, 3.58439210e-21, 3.74903516e-15,\n        1.07501935e-21, 2.37379526e-03, 9.97893933e-13, 5.67676638e-29,\n        2.66118342e-30, 2.76696568e-19, 2.45929399e-17, 3.20988980e-15,\n        1.34981579e-23, 3.15481863e-08, 1.15282530e-22, 1.62811034e-07,\n        1.13790290e-10, 1.06609833e-17, 3.30661288e-19, 1.36794613e-26,\n        5.57576061e-16, 1.87231768e-13, 7.18081629e-21],\n       [2.17307256e-15, 1.00000000e+00, 2.92663717e-27, 0.00000000e+00,\n        2.02870508e-37, 7.36693588e-37, 7.36910408e-21, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.27373323e-09,\n        2.15949103e-34, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 2.25538752e-08, 0.00000000e+00,\n        4.76529717e-29, 0.00000000e+00, 0.00000000e+00, 1.54293877e-38,\n        1.93305253e-36, 1.43101418e-37, 3.55601276e-35, 1.32614119e-28,\n        0.00000000e+00, 3.43878553e-31, 0.00000000e+00, 1.57140941e-30,\n        2.43764877e-36, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 6.72256324e-27, 0.00000000e+00, 0.00000000e+00,\n        2.96716232e-12, 1.65405285e-35, 0.00000000e+00],\n       [0.00000000e+00, 2.51641452e-25, 5.37897252e-33, 0.00000000e+00,\n        0.00000000e+00, 3.54387096e-32, 2.72795164e-31, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n        1.71728979e-25, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.25136065e-38,\n        6.93658647e-22, 5.31652585e-34, 0.00000000e+00, 1.17289251e-31,\n        4.29902308e-18, 1.78873400e-16, 9.90735615e-38, 4.99272235e-10,\n        1.79707568e-26, 3.19192749e-31, 2.16158398e-08, 0.00000000e+00,\n        2.30670700e-34, 4.87379789e-38, 1.76524846e-21, 4.00485804e-38,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        7.04501177e-38, 2.98800520e-27, 1.83396896e-32]], dtype=float32) has invalid type <class 'numpy.ndarray'>, must be a string or Tensor. (Can not convert a ndarray into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "sess2 = tf.get_default_session()\n",
    "\n",
    "with tf.Session() as sess2:\n",
    "    sess2.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess2, tf.train.latest_checkpoint('.'))\n",
    "    test_accuracy = evaluate(preprocessed_img, label)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))\n",
    "    result = sess2.run(softmax, feed_dict={x: preprocessed_img,keep_prob: 1.})\n",
    "    values, indices = tf.nn.top_k(result, 5)\n",
    "    \n",
    "    predictions  = sess2.run(values)\n",
    "    predictionIndicies  = sess2.run(indices)\n",
    "    print(\"predictions\")\n",
    "    print(predictions)\n",
    "    print(\"predictionIndicies\")\n",
    "    print(predictionIndicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image, model_name):\n",
    "    with  tf.Session() as sess:\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "        #softmax = sess.run(tf.nn.softmax(logits), feed_dict={x:preprocessed_img, keep_prob: 1.})\n",
    "        prediction = tf.argmax(logits, 1)\n",
    "        return prediction.eval(feed_dict={x:preprocessed_img, keep_prob: 1.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-2bd78811fa42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'architecture'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msigns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessed_images' is not defined"
     ]
    }
   ],
   "source": [
    "prediction = predict(preprocessed_images[0], 'architecture')\n",
    "prediction = np.asscalar(prediction)\n",
    "plt.imshow(raw_images[0])\n",
    "print(\"Prediction: \" + signs[prediction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

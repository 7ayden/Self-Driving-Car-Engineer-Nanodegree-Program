{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Dropout, ELU\n",
    "from keras.layers.convolutional import Convolution2D, Cropping2D\n",
    "from keras import backend as K\n",
    "\n",
    "def load_driving_log(path='./data', split='\\\\'):\n",
    "    csv = pd.read_csv(os.path.join(path, 'driving_log.csv'), header=None,\n",
    "                          names=['center','left','right','angle','throttle','break','speed'])\n",
    "\n",
    "    csv.center = csv.center.str.split(split).str[-1]\n",
    "    csv.left = csv.left.str.split(split).str[-1]\n",
    "    csv.right = csv.right.str.split(split).str[-1]\n",
    "    return csv\n",
    "\n",
    "def generator(samples, path='./data', batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    print(num_samples)\n",
    "    while 1:\n",
    "        shuffle(samples)\n",
    "    \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            batch_samples = samples[offset:offset + batch_size]\n",
    "\n",
    "            for batch_sample in batch_samples:\n",
    "                name = os.path.join(path, 'IMG', batch_sample[0])\n",
    "                image = cv2.resize(cv2.imread(name), (200, 100), interpolation=cv2.INTER_AREA)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "                images.append(image)\n",
    "                angle = float(batch_sample[3])\n",
    "                angles.append(angle)\n",
    "\n",
    "            yield shuffle(np.array(images), np.array(angles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/CarND-Behavioral-Cloning-P3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-38-4da2c52dc78c>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-4da2c52dc78c>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    filename = source_path.split('\\')[-1]\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "#import data \n",
    "\n",
    "lines = []\n",
    "file_name = \"/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/CarND-Behavioral-Cloning-P3/data/driving_log.csv\"\n",
    "\n",
    "with open(file_name) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "images = []\n",
    "measurements = []\n",
    "\n",
    "for line in lines:\n",
    "    image = cv2.imread(line[0])\n",
    "#assert image is not None\n",
    "    filename = source_path.split('\\\\')[-1]\n",
    "    current_path = '/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/CarND-Behavioral-Cloning-P3/data/IMG/' + filename\n",
    "    image = cv2.imread(current_path)\n",
    "    if image is None:\n",
    "        print(\"Image path incorrect: \", current_path)\n",
    "        continue  # skip adding these rows in the for loop\n",
    "\n",
    "    images.append(image)\n",
    "    measurement= float(line[3])\n",
    "    measurements.append(measurement)\n",
    "\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(160,320,3)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2)\n",
    "\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 320, 3)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "with open(\"/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/CarND-Behavioral-Cloning-P3/data/driving_log.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "for line in lines:\n",
    "    filename = line[0]\n",
    "    current_center = cv2.imread(filename)\n",
    "    images.append(current_center)\n",
    "    \n",
    "print(current_center.shape)\n",
    "print(type(current_center))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: expected flatten_input_9 to have 4 dimensions, but got array with shape (6853, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-312b0841c42c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1118\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1028\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                                    \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m                                    exception_prefix='model input')\n\u001b[0m\u001b[1;32m   1031\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[1;32m   1032\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    110\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: expected flatten_input_9 to have 4 dimensions, but got array with shape (6853, 1)"
     ]
    }
   ],
   "source": [
    "import csv \n",
    "import cv2\n",
    "import numpy as np\n",
    "lines = []\n",
    "with open('/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/CarND-Behavioral-Cloning-P3/data/driving_log.csv')as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "        \n",
    "images = []\n",
    "measurements = []\n",
    "for line in lines:\n",
    "    source_path = line[0]\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = '../data/IMG' + filename\n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "\n",
    "    try:\n",
    "        measurement = float(line[3])\n",
    "        measurements.append(measurement)\n",
    "    except:\n",
    "        # maybe print something like this so blank values are not missed out\n",
    "        # print(\"Error!! Trying to convert %s to float\" % line[3])\n",
    "        print(line[3])\n",
    "    \n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape= (160,320,3)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle= True, nb_epoch=7)\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_driving_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7fdede99ac80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdriving_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_driving_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdriving_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_driving_log' is not defined"
     ]
    }
   ],
   "source": [
    "driving_log = load_driving_log()\n",
    "driving_log.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, validation_samples = train_test_split(driving_log, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Driving log length:', len(driving_log))\n",
    "print('Training samples length:', len(train_samples))\n",
    "print('Validation samples length:', len(validation_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(train_samples))\n",
    "train_generator = generator(list(train_samples), batch_size=32)\n",
    "validation_generator = generator(list(validation_samples), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. define basic model\n",
    "model = Sequential()\n",
    "# 6. add cropping\n",
    "model.add(Cropping2D(cropping=((70, 25), (0, 0)), input_shape=(160, 320, 3)))\n",
    "model.add(Lambda(lambda x: x / 255 - 0.5, trainable=False))\n",
    "model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(64, 3, 3, border_mode=\"valid\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(64, 3, 3, border_mode=\"valid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(ELU())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(ELU())\n",
    "model.add(Dense(50))\n",
    "model.add(ELU())\n",
    "model.add(Dense(10))\n",
    "model.add(ELU())\n",
    "model.add(Dense(1, trainable=False))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>/Users/jaydenmilton/Documents/IMG/center_2018_04_26_19_06_59_225.jpg</th>\n",
       "      <th>/Users/jaydenmilton/Documents/IMG/left_2018_04_26_19_06_59_225.jpg</th>\n",
       "      <th>/Users/jaydenmilton/Documents/IMG/right_2018_04_26_19_06_59_225.jpg</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.8402984</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/center_2018_...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/left_2018_04...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/right_2018_0...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.828530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/center_2018_...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/left_2018_04...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/right_2018_0...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.816926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/center_2018_...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/left_2018_04...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/right_2018_0...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/center_2018_...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/left_2018_04...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/right_2018_0...</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.417969</td>\n",
       "      <td>0</td>\n",
       "      <td>1.473115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/center_2018_...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/left_2018_04...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/right_2018_0...</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.750696</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  /Users/jaydenmilton/Documents/IMG/center_2018_04_26_19_06_59_225.jpg  \\\n",
       "0  /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "1  /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "2  /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "3  /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "4  /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "\n",
       "  /Users/jaydenmilton/Documents/IMG/left_2018_04_26_19_06_59_225.jpg  \\\n",
       "0  /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "1  /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "2  /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "3  /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "4  /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "\n",
       "  /Users/jaydenmilton/Documents/IMG/right_2018_04_26_19_06_59_225.jpg     0  \\\n",
       "0  /Users/jaydenmilton/Documents/IMG/right_2018_0...                   0.00   \n",
       "1  /Users/jaydenmilton/Documents/IMG/right_2018_0...                   0.00   \n",
       "2  /Users/jaydenmilton/Documents/IMG/right_2018_0...                   0.00   \n",
       "3  /Users/jaydenmilton/Documents/IMG/right_2018_0...                  -0.35   \n",
       "4  /Users/jaydenmilton/Documents/IMG/right_2018_0...                  -0.65   \n",
       "\n",
       "        0.1  0.2  0.8402984  \n",
       "0  0.000000    0   0.828530  \n",
       "1  0.000000    0   0.816926  \n",
       "2  0.000000    0   0.803865  \n",
       "3  0.417969    0   1.473115  \n",
       "4  0.750696    0   2.405843  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sample_data = pd.read_csv('/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/CarND-Behavioral-Cloning-P3/data/driving_log.csv')\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'steering'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-6f1dcb1f3383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"steering1.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3614\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'steering'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.distplot(sample_data.steering);\n",
    "plt.savefig(\"steering1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/data/driving_log.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-dc65a7bacdc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading images...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/data/driving_log.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/data/driving_log.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, MaxPooling2D, Conv2D, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "dataset_dir = \"/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/data/IMG\"\n",
    "image_columns = 32\n",
    "image_rows = 16\n",
    "image_channels = 1\n",
    "side_shift = 0.3\n",
    "\n",
    "\n",
    "def preproccess_image(image):\n",
    "    image = (cv2.cvtColor(image, cv2.COLOR_BGR2HSV))[:, :, 1]\n",
    "    image = image.reshape(160, 320, 1)\n",
    "    image = cv2.resize(image, (image_columns, image_rows))\n",
    "    return image\n",
    "\n",
    "\n",
    "def prepare(data):\n",
    "    x, y = [], []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        line_data = data.iloc[i]\n",
    "        y_steer = line_data['steering']\n",
    "        path_center = line_data['center'].strip()\n",
    "        path_left = line_data['left'].strip()\n",
    "        path_right = line_data['right'].strip()\n",
    "\n",
    "        for path, shift in [(path_center, 0), (path_left, side_shift), (path_right, -side_shift)]:\n",
    "            # read image\n",
    "            image_path = os.path.join(dataset_dir, path)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # preprocess image\n",
    "            image = preproccess_image(image)\n",
    "\n",
    "            # add image\n",
    "            x.append(image)\n",
    "            y.append(y_steer + shift)\n",
    "\n",
    "            # add flipped image\n",
    "            image = image[:, ::-1]\n",
    "            x.append(image)\n",
    "            y.append(-(y_steer + shift))\n",
    "\n",
    "    return np.array(x).astype('float32'), np.array(y).astype('float32')\n",
    "\n",
    "\n",
    "def model():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x / 127.5 - 1.0, input_shape=(image_rows, image_columns, image_channels)))\n",
    "    model.add(Conv2D(2, 3, 3, border_mode='valid', activation='elu'))\n",
    "    model.add(MaxPooling2D((4, 4), (4, 4), 'valid'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Loading images...\")\n",
    "\n",
    "    data = pd.read_csv(os.path.join(dataset_dir, \"/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/data/driving_log.csv\"))\n",
    "\n",
    "    X_train, y_train = prepare(data)\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    model = model()\n",
    "    model.compile('adam', 'mean_squared_error', ['mean_squared_error'])\n",
    "    checkpoint = ModelCheckpoint(\"model.h5\", monitor='val_mean_squared_error', verbose=1,\n",
    "                                  save_best_only=True, mode='min')\n",
    "    early_stop = EarlyStopping(monitor='val_mean_squared_error', min_delta=0.0001, patience=4,\n",
    "                                verbose=1, mode='min')\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=epochs, verbose=1,\n",
    "                      callbacks=[checkpoint, early_stop], validation_split=0.15, shuffle=True)\n",
    "\n",
    "    print(\"Saving model...\")\n",
    "    with open(\"model.json\", 'w') as outfile:\n",
    "        outfile.write(model.to_json())\n",
    "\n",
    "    print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data preprocessing \n",
    "\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "\n",
    "model = Sequential()\n",
    "#first normalize the data image\n",
    "model.add = (Lambda(lambda x:x /255.0), input_shape = (160,320,3))\n",
    "#model.add = (Lambda(lambda x:x /255.0 -0.0), input_shape = (160,320,3))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=\"adam\")\n",
    "#reducing the epoch, since the data had been overfitting \n",
    "model.fit(X_train, y_train, validation_split=0.2,shuffle=True, nb_epoch-5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augrementation \n",
    "#numpy/cv2 has that \n",
    "#https://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html#flip\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "image_flipped = np.fliplr(image)\n",
    "measurement_flipped = -measurement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-camera training \n",
    "\n",
    "\n",
    "with open(csv_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            steering_center = float(row[3])\n",
    "\n",
    "            # create adjusted steering measurements for the side camera images\n",
    "            correction = 0.2 # this is a parameter to tune\n",
    "            steering_left = steering_center + correction\n",
    "            steering_right = steering_center - correction\n",
    "\n",
    "            # read in images from center, left and right cameras\n",
    "            path = \"...\" # fill in the path to your training IMG directory\n",
    "            img_center = process_image(np.asarray(Image.open(path + row[0])))\n",
    "            img_left = process_image(np.asarray(Image.open(path + row[1])))\n",
    "            img_right = process_image(np.asarray(Image.open(path + row[2])))\n",
    "\n",
    "            # add images and angles to data set\n",
    "            car_images.extend(img_center, img_left, img_right)\n",
    "            steering_angles.extend(steering_center, steering_left, steering_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copping the image \n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Cropping2D\n",
    "import cv2\n",
    "\n",
    "# set up cropping2D layer\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(3,160,320)))\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nvida network \n",
    "#fewer epoch steps that makes better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing loss \n",
    "\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch =\n",
    "    len(train_samples), validation_data = \n",
    "    validation_generator,\n",
    "    nb_val_samples = len(validation_samples), \n",
    "    nb_epoch=5, verbose=1)\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-50-b1fca75a62ac>, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-b1fca75a62ac>\"\u001b[0;36m, line \u001b[0;32m62\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m       \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "#Generators\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "samples = []\n",
    "with open('./driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = './IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "            '''\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "ch, row, col = 3, 80, 320  # Trimmed image format\n",
    "\n",
    "model = Sequential()\n",
    "# Preprocess incoming data, centered around zero with small standard deviation \n",
    "model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "        input_shape=(ch, row, col),\n",
    "        output_shape=(ch, row, col)))\n",
    "model.add(... finish defining the rest of your model architecture here ...)\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit_generator(train_generator, samples_per_epoch= /\n",
    "            len(train_samples), validation_data=validation_generator, /\n",
    "            nb_val_samples=len(validation_samples), nb_epoch=3)\n",
    "\n",
    "\"\"\"\n",
    "If the above code throw exceptions, try \n",
    "model.fit_generator(train_generator, steps_per_epoch= len(train_samples),\n",
    "validation_data=validation_generator, validation_steps=len(validation_samples), epochs=5, verbose = 1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

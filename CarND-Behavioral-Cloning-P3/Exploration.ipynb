{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Dropout, ELU\n",
    "from keras.layers.convolutional import Convolution2D, Cropping2D\n",
    "from keras import backend as K\n",
    "\n",
    "def load_driving_log(path='./data', split='\\\\'):\n",
    "    csv = pd.read_csv(os.path.join(path, 'driving_log.csv'), header=None,\n",
    "                          names=['center','left','right','angle','throttle','break','speed'])\n",
    "\n",
    "    csv.center = csv.center.str.split(split).str[-1]\n",
    "    csv.left = csv.left.str.split(split).str[-1]\n",
    "    csv.right = csv.right.str.split(split).str[-1]\n",
    "    return csv\n",
    "\n",
    "def generator(samples, path='./data/IMG', batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    print(num_samples)\n",
    "    while 1:\n",
    "        shuffle(samples)\n",
    "    \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            batch_samples = samples[offset:offset + batch_size]\n",
    "\n",
    "            for batch_sample in batch_samples:\n",
    "                name = os.path.join(path, 'IMG', batch_sample[0])\n",
    "                image = cv2.resize(cv2.imread(name), (200, 100), interpolation=cv2.INTER_AREA)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "                images.append(image)\n",
    "                angle = float(batch_sample[3])\n",
    "                angles.append(angle)\n",
    "\n",
    "            yield shuffle(np.array(images), np.array(angles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>brake</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/center_2018_...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/left_2018_04...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/right_2018_0...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.840298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/center_2018_...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/left_2018_04...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/right_2018_0...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.828530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/center_2018_...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/left_2018_04...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/right_2018_0...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.816926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/center_2018_...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/left_2018_04...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/right_2018_0...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.803865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/center_2018_...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/left_2018_04...</td>\n",
       "      <td>/Users/jaydenmilton/Documents/IMG/right_2018_0...</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.417969</td>\n",
       "      <td>0</td>\n",
       "      <td>1.473115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              center  \\\n",
       "0  /Users/jaydenmilton/Documents/IMG/center_2018_...   \n",
       "1  /Users/jaydenmilton/Documents/IMG/center_2018_...   \n",
       "2  /Users/jaydenmilton/Documents/IMG/center_2018_...   \n",
       "3  /Users/jaydenmilton/Documents/IMG/center_2018_...   \n",
       "4  /Users/jaydenmilton/Documents/IMG/center_2018_...   \n",
       "\n",
       "                                                left  \\\n",
       "0  /Users/jaydenmilton/Documents/IMG/left_2018_04...   \n",
       "1  /Users/jaydenmilton/Documents/IMG/left_2018_04...   \n",
       "2  /Users/jaydenmilton/Documents/IMG/left_2018_04...   \n",
       "3  /Users/jaydenmilton/Documents/IMG/left_2018_04...   \n",
       "4  /Users/jaydenmilton/Documents/IMG/left_2018_04...   \n",
       "\n",
       "                                               right  steering  throttle  \\\n",
       "0  /Users/jaydenmilton/Documents/IMG/right_2018_0...      0.00  0.000000   \n",
       "1  /Users/jaydenmilton/Documents/IMG/right_2018_0...      0.00  0.000000   \n",
       "2  /Users/jaydenmilton/Documents/IMG/right_2018_0...      0.00  0.000000   \n",
       "3  /Users/jaydenmilton/Documents/IMG/right_2018_0...      0.00  0.000000   \n",
       "4  /Users/jaydenmilton/Documents/IMG/right_2018_0...     -0.35  0.417969   \n",
       "\n",
       "   brake     speed  \n",
       "0      0  0.840298  \n",
       "1      0  0.828530  \n",
       "2      0  0.816926  \n",
       "3      0  0.803865  \n",
       "4      0  1.473115  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "column_names = ['center', 'left', 'right',\n",
    "                'steering', 'throttle', 'brake', 'speed']\n",
    "df = pd.read_csv('./data/driving_log.csv',names=column_names) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6853, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12babee48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.steering.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6853.000000\n",
       "mean       -0.036254\n",
       "std         0.192461\n",
       "min        -1.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000\n",
       "Name: steering, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.steering.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6853\n",
       "Name: brake, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.brake.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12baaf1d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.query('steering != 0')['steering'].plot.hist(bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import PurePosixPath\n",
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = df.values\n",
    "images = []\n",
    "measurements = []\n",
    "#for each driving data\n",
    "for line in lines:\n",
    "    steering_center = float(line[3])\n",
    "    # create adjusted steering measurements for the side camera images\n",
    "    correction = 0.6 # this is a parameter to tune\n",
    "    steering_left = steering_center + correction\n",
    "    steering_right = steering_center - correction\n",
    "\n",
    "    # read in images from center, left and right cameras\n",
    "    path = \"./data/IMG/\" # fill in the path to your training IMG directory\n",
    "    img_center = cv2.imread(path + line[0].split('/')[-1])\n",
    "    img_left = cv2.imread(path + line[1].split('/')[-1])\n",
    "    img_right = cv2.imread(path + line[2].split('/')[-1])\n",
    "\n",
    "    # add images and angles to data set\n",
    "    images.extend([img_center, img_left, img_right])\n",
    "    measurements.extend([steering_center, steering_left, steering_right])\n",
    "    source_path = line[0]\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = './data/IMG/'+filename\n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "    measurement = float(line[3]) \n",
    "    measurements.append(measurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-30-0530ed634df3>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-0530ed634df3>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    figfig  ==  pltplt..figurefigure()()\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "figfig  ==  pltplt..figurefigure()()\n",
    " # Center Image# Cente \n",
    "ax1 = fig.add_subplot(3,1,1)\n",
    "#ax1.title(\"Center Image\")\n",
    "ax1.axis('off')\n",
    "ax1.imshow(images[0])\n",
    "\n",
    "# Left Image\n",
    "ax2 = fig.add_subplot(3,1,2)\n",
    "#ax2.title(\"Left Image\")\n",
    "ax2.axis('off')\n",
    "ax2.imshow(images[1])\n",
    "\n",
    "# Right Image\n",
    "ax3 = fig.add_subplot(3,1,3)\n",
    "#ax3.title(\"Right Image\")\n",
    "ax3.axis('off')\n",
    "ax3.imshow(images[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/CarND-Behavioral-Cloning-P3/data'\n",
    "center_camera_files=image_files(path+'/IMG/')\n",
    "left_camera_files=image_files(path+'/IMG/',camera='left')\n",
    "right_camera_files=image_files(path+'/IMG/',camera='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4966 4966 4966\n"
     ]
    }
   ],
   "source": [
    "print(len(left_camera_files),len(center_camera_files),len(right_camera_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_from_row(row, image_preprocess=lambda x: x):\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(10, 5))\n",
    "    image = plt.imread(path+ row['left'].strip())\n",
    "    ax1.imshow(idf(image))\n",
    "    ax1.grid(False)\n",
    "    \n",
    "    image = plt.imread(path+ row['center'])\n",
    "    ax2.imshow(df(image))\n",
    "    ax2.grid(False)\n",
    "    image = plt.imread(path+ row['right'].strip())\n",
    "    ax3.imshow(df(image))\n",
    "    ax3.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/CarND-Behavioral-Cloning-P3/data/Users/jaydenmilton/Documents/IMG/left_2018_04_26_19_06_59_225.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6170ac7c3f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mno_turn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'steering'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_images_from_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_turn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-eaf120aafeda>\u001b[0m in \u001b[0;36mplot_images_from_row\u001b[0;34m(row, image_preprocess)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_images_from_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_preprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2379\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2381\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpilread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             raise ValueError('Only know how to handle extensions: %s; '\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mpilread\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2543\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2544\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/CarND-Behavioral-Cloning-P3/data/Users/jaydenmilton/Documents/IMG/left_2018_04_26_19_06_59_225.jpg'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "no_turn = df[df['steering'] == 0.0 ].iloc[0]\n",
    "plot_images_from_row(no_turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  moviepy.editor import *\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_movie_from_log(log_path,log_file='driving_log.csv',skiprows=1,clip_name='log_clip.mp4', sample_every=1):\n",
    "    column_names = ['center', 'left', 'right',\n",
    "                    'steering', 'throttle', 'brake', 'speed']\n",
    "    data_df = pd.read_csv(log_path+'/'+log_file,\n",
    "                          names=column_names, skiprows=skiprows)\n",
    "    \n",
    "    clip_data=[load_and_draw(data_df, log_path, idx) for idx in data_df.index if not idx % sample_every]\n",
    "    clip = ImageSequenceClip(clip_data, fps=50)\n",
    "    %time clip.write_videofile(clip_name, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clip_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8014b80ef5b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclip_nameclip_nam\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'udacity_sample.mp4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcreate_movie_from_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/u200/Udacity/behavioral-cloning-project/data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclip_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clip_name' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "clip_nameclip_nam ='udacity_sample.mp4'\n",
    "create_movie_from_log('/u200/Udacity/behavioral-cloning-project/data',skiprows=1,clip_name=clip_name,sample_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=4.1.0                    \u001b[34mdata\u001b[m\u001b[m/                     model.py.ipynb\r\n",
      "\u001b[34mCarND-Behavioral-Cloning\u001b[m\u001b[m/ drive.py                  \u001b[34mrun1\u001b[m\u001b[m/\r\n",
      "Exploration.ipynb         \u001b[34mexamples\u001b[m\u001b[m/                 steering1.png\r\n",
      "LICENSE                   model.h5                  video.py\r\n",
      "README.md                 model.json                writeup_template.md\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "def show_images(images, labels, rows=4, cols=5, figsize=(20,10), gray=False):\n",
    "    images_to_show = len(images)\n",
    "    fig, axis = plt.subplots(rows, cols, figsize=figsize)\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axis = axis.ravel()\n",
    "    for i in range(images_to_show):\n",
    "        image = images[i]\n",
    "        axis[i].axis('off')\n",
    "        if (gray):\n",
    "            axis[i].imshow(image.squeeze(), cmap='gray')\n",
    "        else:\n",
    "            axis[i].imshow(image)\n",
    "        axis[i].set_title(labels[i])\n",
    "\n",
    "def show_random_image(X,y,rows=4, cols=5, figsize=(20,10),gray=False):\n",
    "    # show images of random data points\n",
    "    images_to_show = 4\n",
    "    images = []\n",
    "    labels =[]\n",
    "    for i in range(images_to_show):\n",
    "        index = random.randint(0, len(X))\n",
    "        images.append(X[index])\n",
    "        labels.append(y[index])\n",
    "\n",
    "    show_images(images,labels,rows,cols,figsize,gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-883752aa14f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_random_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-8b7a5bceae86>\u001b[0m in \u001b[0;36mshow_random_image\u001b[0;34m(X, y, rows, cols, figsize, gray)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mshow_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-8b7a5bceae86>\u001b[0m in \u001b[0;36mshow_images\u001b[0;34m(images, labels, rows, cols, figsize, gray)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0maxis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5485\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    647\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    648\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[0;32m--> 649\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image data cannot be converted to float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         if not (self._A.ndim == 2\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_image(X_train, y_train, 2, 2, (18,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: expected flatten_input_1 to have 4 dimensions, but got array with shape (0, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d582ba81cb42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1118\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1028\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                                    \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m                                    exception_prefix='model input')\n\u001b[0m\u001b[1;32m   1031\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[1;32m   1032\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    110\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: expected flatten_input_1 to have 4 dimensions, but got array with shape (0, 1)"
     ]
    }
   ],
   "source": [
    "#import data \n",
    "\n",
    "lines = []\n",
    "df = pd.read_csv(\"/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/CarND-Behavioral-Cloning-P3/data/driving_log.csv\")\n",
    "df.describe(include='all')\n",
    "'''\n",
    "with open(file_name) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "'''\n",
    "images = []\n",
    "measurements = []\n",
    "\n",
    "for line in lines:\n",
    "#    image = cv2.imread(line[0])\n",
    "    source_path=line[0]\n",
    "#assert image is not None\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = '/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/CarND-Behavioral-Cloning-P3/data/IMG/' + filename\n",
    "    image = cv2.imread(current_path)\n",
    "    if image is None:\n",
    "        print(\"Image path incorrect: \", current_path)\n",
    "        continue  # skip adding these rows in the for loop\n",
    "\n",
    "    images.append(image)\n",
    "    measurement= float(line[3])\n",
    "    measurements.append(measurement)\n",
    "\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(160,320,3)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.2)\n",
    "\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/CarND-Behavioral-Cloning-P3'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      /Users/jaydenmilton/Documents/IMG/center_2018_04_26_19_06_59_225.jpg  \\\n",
       "0     /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "1     /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "2     /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "3     /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "4     /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "5     /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "6     /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "7     /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "8     /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "9     /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "10    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "11    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "12    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "13    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "14    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "15    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "16    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "17    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "18    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "19    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "20    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "21    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "22    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "23    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "24    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "25    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "26    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "27    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "28    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "29    /Users/jaydenmilton/Documents/IMG/center_2018_...                     \n",
       "...                                                 ...                     \n",
       "6822  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6823  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6824  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6825  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6826  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6827  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6828  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6829  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6830  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6831  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6832  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6833  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6834  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6835  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6836  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6837  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6838  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6839  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6840  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6841  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6842  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6843  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6844  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6845  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6846  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6847  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6848  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6849  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6850  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "6851  /Users/jaydenmilton/Documents/Self-Driving-Car...                     \n",
       "\n",
       "     /Users/jaydenmilton/Documents/IMG/left_2018_04_26_19_06_59_225.jpg  \\\n",
       "0     /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "1     /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "2     /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "3     /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "4     /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "5     /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "6     /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "7     /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "8     /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "9     /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "10    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "11    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "12    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "13    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "14    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "15    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "16    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "17    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "18    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "19    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "20    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "21    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "22    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "23    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "24    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "25    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "26    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "27    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "28    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "29    /Users/jaydenmilton/Documents/IMG/left_2018_04...                   \n",
       "...                                                 ...                   \n",
       "6822  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6823  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6824  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6825  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6826  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6827  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6828  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6829  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6830  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6831  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6832  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6833  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6834  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6835  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6836  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6837  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6838  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6839  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6840  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6841  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6842  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6843  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6844  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6845  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6846  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6847  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6848  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6849  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6850  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "6851  /Users/jaydenmilton/Documents/Self-Driving-Car...                   \n",
       "\n",
       "     /Users/jaydenmilton/Documents/IMG/right_2018_04_26_19_06_59_225.jpg  \\\n",
       "0     /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "1     /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "2     /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "3     /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "4     /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "5     /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "6     /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "7     /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "8     /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "9     /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "10    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "11    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "12    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "13    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "14    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "15    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "16    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "17    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "18    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "19    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "20    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "21    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "22    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "23    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "24    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "25    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "26    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "27    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "28    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "29    /Users/jaydenmilton/Documents/IMG/right_2018_0...                    \n",
       "...                                                 ...                    \n",
       "6822  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6823  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6824  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6825  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6826  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6827  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6828  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6829  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6830  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6831  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6832  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6833  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6834  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6835  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6836  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6837  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6838  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6839  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6840  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6841  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6842  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6843  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6844  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6845  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6846  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6847  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6848  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6849  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6850  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "6851  /Users/jaydenmilton/Documents/Self-Driving-Car...                    \n",
       "\n",
       "             0  \n",
       "0     0.000000  \n",
       "1     0.000000  \n",
       "2     0.000000  \n",
       "3    -0.350000  \n",
       "4    -0.650000  \n",
       "5    -0.850000  \n",
       "6    -0.778234  \n",
       "7    -0.560035  \n",
       "8     0.000000  \n",
       "9     0.000000  \n",
       "10    0.000000  \n",
       "11    0.000000  \n",
       "12    0.000000  \n",
       "13    0.000000  \n",
       "14    0.000000  \n",
       "15   -0.350000  \n",
       "16   -0.016176  \n",
       "17    0.000000  \n",
       "18   -0.200000  \n",
       "19   -0.500000  \n",
       "20   -0.254724  \n",
       "21   -0.704724  \n",
       "22   -0.954724  \n",
       "23   -1.000000  \n",
       "24   -0.661957  \n",
       "25    0.000000  \n",
       "26    0.000000  \n",
       "27    0.000000  \n",
       "28    0.000000  \n",
       "29    0.200000  \n",
       "...        ...  \n",
       "6822  0.000000  \n",
       "6823  0.000000  \n",
       "6824  0.000000  \n",
       "6825  0.000000  \n",
       "6826  0.000000  \n",
       "6827 -0.150000  \n",
       "6828 -0.226887  \n",
       "6829  0.000000  \n",
       "6830  0.000000  \n",
       "6831  0.000000  \n",
       "6832  0.000000  \n",
       "6833  0.000000  \n",
       "6834  0.000000  \n",
       "6835  0.000000  \n",
       "6836  0.000000  \n",
       "6837  0.000000  \n",
       "6838  0.000000  \n",
       "6839 -0.150000  \n",
       "6840 -0.300000  \n",
       "6841 -0.510198  \n",
       "6842 -0.289086  \n",
       "6843 -0.057645  \n",
       "6844  0.000000  \n",
       "6845  0.000000  \n",
       "6846  0.000000  \n",
       "6847  0.000000  \n",
       "6848  0.000000  \n",
       "6849  0.000000  \n",
       "6850  0.000000  \n",
       "6851  0.000000  \n",
       "\n",
       "[6852 rows x 4 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/CarND-Behavioral-Cloning-P3/data/driving_log.csv', usecols=[0,1,2,3])\n",
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3520 entries, 0 to 3519\n",
      "Data columns (total 7 columns):\n",
      "center      3520 non-null object\n",
      "left        3520 non-null object\n",
      "right       3520 non-null object\n",
      "angle       3520 non-null object\n",
      "throttle    3520 non-null object\n",
      "break       3520 non-null object\n",
      "speed       3520 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 192.6+ KB\n"
     ]
    }
   ],
   "source": [
    "driving_log = load_driving_log()\n",
    "driving_log.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>angle</th>\n",
       "      <th>throttle</th>\n",
       "      <th>break</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.48E-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.29E-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.89E-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.43E-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>/Users/jaydenyuen/Documents/Self-Driving-Car-E...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1398872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0505136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              center  \\\n",
       "0  /Users/jaydenyuen/Documents/Self-Driving-Car-E...   \n",
       "1  /Users/jaydenyuen/Documents/Self-Driving-Car-E...   \n",
       "2  /Users/jaydenyuen/Documents/Self-Driving-Car-E...   \n",
       "3  /Users/jaydenyuen/Documents/Self-Driving-Car-E...   \n",
       "4  /Users/jaydenyuen/Documents/Self-Driving-Car-E...   \n",
       "\n",
       "                                                left  \\\n",
       "0  /Users/jaydenyuen/Documents/Self-Driving-Car-E...   \n",
       "1  /Users/jaydenyuen/Documents/Self-Driving-Car-E...   \n",
       "2  /Users/jaydenyuen/Documents/Self-Driving-Car-E...   \n",
       "3  /Users/jaydenyuen/Documents/Self-Driving-Car-E...   \n",
       "4  /Users/jaydenyuen/Documents/Self-Driving-Car-E...   \n",
       "\n",
       "                                               right angle   throttle break  \\\n",
       "0  /Users/jaydenyuen/Documents/Self-Driving-Car-E...     0          0     0   \n",
       "1  /Users/jaydenyuen/Documents/Self-Driving-Car-E...     0          0     0   \n",
       "2  /Users/jaydenyuen/Documents/Self-Driving-Car-E...     0          0     0   \n",
       "3  /Users/jaydenyuen/Documents/Self-Driving-Car-E...     0          0     0   \n",
       "4  /Users/jaydenyuen/Documents/Self-Driving-Car-E...     0  0.1398872     0   \n",
       "\n",
       "       speed  \n",
       "0   6.48E-06  \n",
       "1   5.29E-06  \n",
       "2   3.89E-06  \n",
       "3   2.43E-06  \n",
       "4  0.0505136  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, validation_samples = train_test_split(driving_log, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driving log length: 3520\n",
      "Training samples length: 2816\n",
      "Validation samples length: 704\n"
     ]
    }
   ],
   "source": [
    "print('Driving log length:', len(driving_log))\n",
    "print('Training samples length:', len(train_samples))\n",
    "print('Validation samples length:', len(validation_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['center', 'left', 'right', 'angle', 'throttle', 'break', 'speed']\n"
     ]
    }
   ],
   "source": [
    "print(list(train_samples))\n",
    "train_generator = generator(list(train_samples), batch_size=32)\n",
    "validation_generator = generator(list(validation_samples), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "cropping2d_1 (Cropping2D)        (None, 65, 320, 3)    0           cropping2d_input_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 65, 320, 3)    0           cropping2d_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 31, 158, 24)   1824        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "elu_1 (ELU)                      (None, 31, 158, 24)   0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 14, 77, 36)    21636       elu_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_2 (ELU)                      (None, 14, 77, 36)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 5, 37, 48)     43248       elu_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_3 (ELU)                      (None, 5, 37, 48)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 3, 35, 64)     27712       elu_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_4 (ELU)                      (None, 3, 35, 64)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 1, 33, 64)     36928       elu_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1, 33, 64)     0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "elu_5 (ELU)                      (None, 1, 33, 64)     0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 2112)          0           elu_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 100)           211300      flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_6 (ELU)                      (None, 100)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 50)            5050        elu_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_7 (ELU)                      (None, 50)            0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 10)            510         elu_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "elu_8 (ELU)                      (None, 10)            0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             11          elu_8[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 348,219\n",
      "Trainable params: 348,208\n",
      "Non-trainable params: 11\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. define basic model\n",
    "model = Sequential()\n",
    "# 6. add cropping\n",
    "model.add(Cropping2D(cropping=((70, 25), (0, 0)), input_shape=(160, 320, 3)))\n",
    "model.add(Lambda(lambda x: x / 255 - 0.5, trainable=False))\n",
    "model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"valid\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(64, 3, 3, border_mode=\"valid\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(64, 3, 3, border_mode=\"valid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(ELU())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(ELU())\n",
    "model.add(Dense(50))\n",
    "model.add(ELU())\n",
    "model.add(Dense(10))\n",
    "model.add(ELU())\n",
    "model.add(Dense(1, trainable=False))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'steering'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0013af23de10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriving_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"steering1.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3614\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'steering'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.distplot(driving_log.steering);\n",
    "plt.savefig(\"steering1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/data/driving_log.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-dc65a7bacdc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading images...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/data/driving_log.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/data/driving_log.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, MaxPooling2D, Conv2D, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "dataset_dir = \"/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/data/IMG\"\n",
    "image_columns = 32\n",
    "image_rows = 16\n",
    "image_channels = 1\n",
    "side_shift = 0.3\n",
    "\n",
    "\n",
    "def preproccess_image(image):\n",
    "    image = (cv2.cvtColor(image, cv2.COLOR_BGR2HSV))[:, :, 1]\n",
    "    image = image.reshape(160, 320, 1)\n",
    "    image = cv2.resize(image, (image_columns, image_rows))\n",
    "    return image\n",
    "\n",
    "\n",
    "def prepare(data):\n",
    "    x, y = [], []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        line_data = data.iloc[i]\n",
    "        y_steer = line_data['steering']\n",
    "        path_center = line_data['center'].strip()\n",
    "        path_left = line_data['left'].strip()\n",
    "        path_right = line_data['right'].strip()\n",
    "\n",
    "        for path, shift in [(path_center, 0), (path_left, side_shift), (path_right, -side_shift)]:\n",
    "            # read image\n",
    "            image_path = os.path.join(dataset_dir, path)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # preprocess image\n",
    "            image = preproccess_image(image)\n",
    "\n",
    "            # add image\n",
    "            x.append(image)\n",
    "            y.append(y_steer + shift)\n",
    "\n",
    "            # add flipped image\n",
    "            image = image[:, ::-1]\n",
    "            x.append(image)\n",
    "            y.append(-(y_steer + shift))\n",
    "\n",
    "    return np.array(x).astype('float32'), np.array(y).astype('float32')\n",
    "\n",
    "\n",
    "def model():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x / 127.5 - 1.0, input_shape=(image_rows, image_columns, image_channels)))\n",
    "    model.add(Conv2D(2, 3, 3, border_mode='valid', activation='elu'))\n",
    "    model.add(MaxPooling2D((4, 4), (4, 4), 'valid'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Loading images...\")\n",
    "\n",
    "    data = pd.read_csv(os.path.join(dataset_dir, \"/Users/jaydenmilton/Documents/Self-Driving-Car-Engineer-Nanodegree-Program/data/driving_log.csv\"))\n",
    "\n",
    "    X_train, y_train = prepare(data)\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    model = model()\n",
    "    model.compile('adam', 'mean_squared_error', ['mean_squared_error'])\n",
    "    checkpoint = ModelCheckpoint(\"model.h5\", monitor='val_mean_squared_error', verbose=1,\n",
    "                                  save_best_only=True, mode='min')\n",
    "    early_stop = EarlyStopping(monitor='val_mean_squared_error', min_delta=0.0001, patience=4,\n",
    "                                verbose=1, mode='min')\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=epochs, verbose=1,\n",
    "                      callbacks=[checkpoint, early_stop], validation_split=0.15, shuffle=True)\n",
    "\n",
    "    print(\"Saving model...\")\n",
    "    with open(\"model.json\", 'w') as outfile:\n",
    "        outfile.write(model.to_json())\n",
    "\n",
    "    print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data preprocessing \n",
    "\n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "\n",
    "model = Sequential()\n",
    "#first normalize the data image\n",
    "model.add = (Lambda(lambda x:x /255.0), input_shape = (160,320,3))\n",
    "#model.add = (Lambda(lambda x:x /255.0 -0.0), input_shape = (160,320,3))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=\"adam\")\n",
    "#reducing the epoch, since the data had been overfitting \n",
    "model.fit(X_train, y_train, validation_split=0.2,shuffle=True, nb_epoch-5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augrementation \n",
    "#numpy/cv2 has that \n",
    "#https://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html#flip\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "image_flipped = np.fliplr(image)\n",
    "measurement_flipped = -measurement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-camera training \n",
    "\n",
    "\n",
    "with open(csv_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            steering_center = float(row[3])\n",
    "\n",
    "            # create adjusted steering measurements for the side camera images\n",
    "            correction = 0.2 # this is a parameter to tune\n",
    "            steering_left = steering_center + correction\n",
    "            steering_right = steering_center - correction\n",
    "\n",
    "            # read in images from center, left and right cameras\n",
    "            path = \"...\" # fill in the path to your training IMG directory\n",
    "            img_center = process_image(np.asarray(Image.open(path + row[0])))\n",
    "            img_left = process_image(np.asarray(Image.open(path + row[1])))\n",
    "            img_right = process_image(np.asarray(Image.open(path + row[2])))\n",
    "\n",
    "            # add images and angles to data set\n",
    "            car_images.extend(img_center, img_left, img_right)\n",
    "            steering_angles.extend(steering_center, steering_left, steering_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copping the image \n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Cropping2D\n",
    "import cv2\n",
    "\n",
    "# set up cropping2D layer\n",
    "model = Sequential()\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(3,160,320)))\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nvida network \n",
    "#fewer epoch steps that makes better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing loss \n",
    "\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch =\n",
    "    len(train_samples), validation_data = \n",
    "    validation_generator,\n",
    "    nb_val_samples = len(validation_samples), \n",
    "    nb_epoch=5, verbose=1)\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-50-b1fca75a62ac>, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-50-b1fca75a62ac>\"\u001b[0;36m, line \u001b[0;32m62\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m       \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "#Generators\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "samples = []\n",
    "with open('./driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = './IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "            '''\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "ch, row, col = 3, 80, 320  # Trimmed image format\n",
    "\n",
    "model = Sequential()\n",
    "# Preprocess incoming data, centered around zero with small standard deviation \n",
    "model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "        input_shape=(ch, row, col),\n",
    "        output_shape=(ch, row, col)))\n",
    "model.add(... finish defining the rest of your model architecture here ...)\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit_generator(train_generator, samples_per_epoch= /\n",
    "            len(train_samples), validation_data=validation_generator, /\n",
    "            nb_val_samples=len(validation_samples), nb_epoch=3)\n",
    "\n",
    "\"\"\"\n",
    "If the above code throw exceptions, try \n",
    "model.fit_generator(train_generator, steps_per_epoch= len(train_samples),\n",
    "validation_data=validation_generator, validation_steps=len(validation_samples), epochs=5, verbose = 1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
